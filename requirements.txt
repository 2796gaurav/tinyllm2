# Core Dependencies
torch>=2.5.0
transformers>=4.45.0
accelerate>=0.34.0
datasets>=2.20.0
tokenizers>=0.20.0
huggingface_hub>=0.23.0  # For HF_TOKEN authentication

# Training & Optimization
wandb>=0.17.0
optuna>=3.6.0
deepspeed>=0.14.0  # Optional, for multi-GPU
bitsandbytes>=0.43.0  # For INT4 quantization

onnxscript
onnxruntime
# Data Processing
pandas>=2.2.0
numpy>=1.26.0
scikit-learn>=1.5.0
nltk>=3.8.0
sentencepiece>=0.2.0

# Augmentation
augly>=1.0.0
textaugment>=1.3.4

# Evaluation & Metrics
evaluate>=0.4.0
rouge-score>=0.1.2
bert-score>=0.3.13

# Visualization
matplotlib>=3.9.0
seaborn>=0.13.0
plotly>=5.22.0
tensorboard>=2.17.0

# Quantization & Export
onnx>=1.16.0
onnxscript>=0.1.0  # Required for ONNX export (PyTorch 2.0+)
onnxruntime>=1.18.0
onnxruntime-gpu>=1.18.0  # For GPU inference
optimum>=1.21.0

# API & Serving
fastapi>=0.111.0
uvicorn>=0.30.0
pydantic>=2.7.0
python-multipart>=0.0.9

# AWS SageMaker (for cloud training)
boto3>=1.34.0
sagemaker>=2.200.0

# Utilities
tqdm>=4.66.0
pyyaml>=6.0.0
python-dotenv>=1.0.0
rich>=13.7.0  # Beautiful terminal output
typer>=0.12.0  # CLI
loguru>=0.7.0  # Better logging

# Testing
pytest>=8.2.0
pytest-cov>=5.0.0
hypothesis>=6.103.0

# Code Quality
black>=24.4.0
flake8>=7.0.0
mypy>=1.10.0
pre-commit>=3.7.0

# Jupyter (for Colab)
jupyter>=1.0.0
ipywidgets>=8.1.0
notebook>=7.2.0

# Security & Attack Generation
unidecode>=1.3.8  # For homoglyph generation
python-Levenshtein>=0.25.0  # For similarity metrics
ftfy>=6.2.0  # Text fixing

# MLCommons benchmarks (if available)
# jailbreakbench  # Install from source if needed

# Optional: Hardware acceleration
# triton>=2.3.0  # For custom CUDA kernels (advanced)

# Development tools
ipdb>=0.13.13
ipython>=8.24.0

